#!/usr/bin/env python3
"""
ä¼˜åŒ–åæ‰¹é‡å¤„ç†æµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºæµ‹è¯•ä¼˜åŒ–åçš„æ‰¹é‡å¤„ç†åŠŸèƒ½ï¼ŒéªŒè¯ï¼š
1. æŸ¥è¯¢é™åˆ¶è°ƒæ•´ä¸º5æ¡
2. æ™ºèƒ½è¿‡æ»¤æœªå¤„ç†è®°å½•
3. æ‰¹é‡å¤„ç†é€»è¾‘
4. è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

æµ‹è¯•é‡ç‚¹ï¼š
- æŸ¥è¯¢5æ¡æ•°æ®
- è¯†åˆ«å·²å¤„ç†å’Œæœªå¤„ç†è®°å½•
- æ‰¹é‡å¤„ç†æœªå¤„ç†è®°å½•
- ç»Ÿè®¡ä¿¡æ¯çš„å‡†ç¡®æ€§

ä½œè€…ï¼šMCPå›¾åƒè¯†åˆ«ç³»ç»Ÿ
ç‰ˆæœ¬ï¼š3.0.0
"""

import asyncio
import sys
import os
import logging
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(project_root, 'core', 'src')
sys.path.insert(0, src_path)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_query_with_new_limit():
    """æµ‹è¯•æ–°çš„æŸ¥è¯¢é™åˆ¶"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•æŸ¥è¯¢é™åˆ¶è°ƒæ•´...")
    
    try:
        # å¯¼å…¥MCPå·¥å…·
        sys.path.insert(0, os.path.join(project_root, 'core', 'servers'))
        from mcp_server_final import query_image_data
        
        # æµ‹è¯•é»˜è®¤æŸ¥è¯¢ï¼ˆåº”è¯¥æ˜¯5æ¡ï¼‰
        logger.info("ğŸ“Š æµ‹è¯•é»˜è®¤æŸ¥è¯¢é™åˆ¶...")
        query_result = await query_image_data()
        query_data = json.loads(query_result)
        
        logger.info(f"âœ… æŸ¥è¯¢æˆåŠŸ: {query_data['success']}")
        logger.info(f"ğŸ“Š æŸ¥è¯¢åˆ°æ•°æ®: {query_data['count']} æ¡")
        logger.info(f"ğŸ¯ æŸ¥è¯¢é™åˆ¶: {query_data['metadata']['query_limit']}")
        
        # æ˜¾ç¤ºæŸ¥è¯¢åˆ°çš„æ•°æ®æ¦‚è¦
        if query_data['success'] and query_data['count'] > 0:
            logger.info("ğŸ“‹ æ•°æ®æ¦‚è¦:")
            for i, item in enumerate(query_data['data']):
                has_result = bool(item['results']['result_1'].strip())
                status = "å·²å¤„ç†" if has_result else "æœªå¤„ç†"
                logger.info(f"  {i+1}. ID: {item['id'][:8]}... - {status}")
                if item['description']:
                    logger.info(f"     æè¿°: {item['description'][:30]}...")
        
        return True, query_data
        
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False, None

async def test_processing_status():
    """æµ‹è¯•å¤„ç†çŠ¶æ€æŸ¥è¯¢"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•å¤„ç†çŠ¶æ€æŸ¥è¯¢...")
    
    try:
        # å¯¼å…¥çŠ¶æ€æŸ¥è¯¢å·¥å…·
        sys.path.insert(0, os.path.join(project_root, 'core', 'servers'))
        from mcp_server_final import get_processing_status
        
        # æŸ¥è¯¢å¤„ç†çŠ¶æ€
        logger.info("ğŸ“ˆ æŸ¥è¯¢å¤„ç†çŠ¶æ€...")
        status_result = await get_processing_status()
        status_data = json.loads(status_result)
        
        logger.info(f"âœ… çŠ¶æ€æŸ¥è¯¢æˆåŠŸ: {status_data['success']}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = status_data['data_statistics']
        logger.info("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        logger.info(f"  æ€»è®°å½•æ•°: {stats['total_records']}")
        logger.info(f"  å·²å¤„ç†: {stats['processed_records']}")
        logger.info(f"  æœªå¤„ç†: {stats['unprocessed_records']}")
        logger.info(f"  å¤„ç†ç‡: {stats['processing_rate']}")
        
        return True, status_data
        
    except Exception as e:
        logger.error(f"âŒ çŠ¶æ€æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
        return False, None

async def test_batch_processing():
    """æµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½...")
    
    try:
        # å¯¼å…¥æ‰¹é‡å¤„ç†å·¥å…·
        sys.path.insert(0, os.path.join(project_root, 'core', 'servers'))
        from mcp_server_final import batch_process_images
        
        # æ‰§è¡Œæ‰¹é‡å¤„ç†ï¼ˆå°æ‰¹é‡æµ‹è¯•ï¼‰
        logger.info("ğŸ”„ æ‰§è¡Œæ‰¹é‡å¤„ç†...")
        batch_result = await batch_process_images(limit=5, max_concurrent=1)
        batch_data = json.loads(batch_result)
        
        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ: {batch_data['success']}")
        logger.info(f"ğŸ“ å¤„ç†æ¶ˆæ¯: {batch_data['message']}")
        
        # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
        stats = batch_data['statistics']
        logger.info("ğŸ“Š æ‰¹é‡å¤„ç†ç»Ÿè®¡:")
        logger.info(f"  æŸ¥è¯¢æ€»æ•°: {stats['total_queried']}")
        logger.info(f"  å·²å¤„ç†: {stats.get('already_processed', 0)}")
        logger.info(f"  å¾…å¤„ç†: {stats.get('unprocessed_found', 0)}")
        logger.info(f"  æ–°å¤„ç†: {stats.get('newly_processed', 0)}")
        logger.info(f"  å¤±è´¥æ•°: {stats.get('failed', 0)}")
        logger.info(f"  æˆåŠŸç‡: {stats.get('success_rate', '0%')}")
        logger.info(f"  æ€»å¤„ç†ç‡: {stats.get('overall_processing_rate', '0%')}")
        
        # æ˜¾ç¤ºå¤„ç†æ‘˜è¦
        if 'summary' in batch_data:
            summary = batch_data['summary']
            logger.info("ğŸ“‹ å¤„ç†æ‘˜è¦:")
            logger.info(f"  å¤„ç†å‰: {summary['before_processing']}")
            logger.info(f"  å¤„ç†å: {summary['after_processing']}")
            logger.info(f"  æ”¹è¿›: {summary['improvement']}")
        
        # æ˜¾ç¤ºå¤„ç†è¯¦æƒ…
        if 'processing_details' in batch_data and batch_data['processing_details']:
            logger.info("ğŸ” å¤„ç†è¯¦æƒ…:")
            for detail in batch_data['processing_details']:
                status_icon = "âœ…" if detail['status'] == 'success' else "âŒ"
                logger.info(f"  {status_icon} {detail['id'][:8]}... - {detail['status']}")
                if detail.get('error'):
                    logger.info(f"     é”™è¯¯: {detail['error'][:50]}...")
        
        return True, batch_data
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False, None

async def test_configuration_update():
    """æµ‹è¯•é…ç½®æ›´æ–°"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•é…ç½®æ›´æ–°...")
    
    try:
        # å¯¼å…¥é…ç½®èµ„æº
        sys.path.insert(0, os.path.join(project_root, 'core', 'servers'))
        from mcp_server_final import get_server_config
        
        # è·å–æœåŠ¡å™¨é…ç½®
        logger.info("ğŸ“‹ è·å–æœåŠ¡å™¨é…ç½®...")
        config_result = get_server_config()
        config_data = json.loads(config_result)
        
        logger.info(f"âœ… é…ç½®è·å–æˆåŠŸ")
        logger.info(f"  æœåŠ¡å™¨ç‰ˆæœ¬: {config_data['server']['version']}")
        logger.info(f"  å·¥å…·æ•°é‡: {len(config_data['tools'])}")
        
        # æ£€æŸ¥å·¥å…·é…ç½®
        logger.info("ğŸ”§ å·¥å…·é…ç½®:")
        for tool in config_data['tools']:
            logger.info(f"  - {tool['name']}: {tool['description']}")
            if tool['name'] == 'query_image_data':
                params = tool['parameters']
                logger.info(f"    é»˜è®¤é™åˆ¶: {params.get('limit', 'æœªæŒ‡å®š')}")
            elif tool['name'] == 'batch_process_images':
                params = tool['parameters']
                logger.info(f"    é»˜è®¤é™åˆ¶: {params.get('limit', 'æœªæŒ‡å®š')}")
                logger.info(f"    é»˜è®¤å¹¶å‘: {params.get('max_concurrent', 'æœªæŒ‡å®š')}")
        
        return True, config_data
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False, None

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ä¼˜åŒ–åæ‰¹é‡å¤„ç†æµ‹è¯•...")
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æŸ¥è¯¢é™åˆ¶è°ƒæ•´", test_query_with_new_limit),
        ("å¤„ç†çŠ¶æ€æŸ¥è¯¢", test_processing_status),
        ("æ‰¹é‡å¤„ç†åŠŸèƒ½", test_batch_processing),
        ("é…ç½®æ›´æ–°éªŒè¯", test_configuration_update)
    ]
    
    for test_name, test_func in tests:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ§ª æµ‹è¯•: {test_name}")
        logger.info(f"{'='*60}")
        
        try:
            result, data = await test_func()
            test_results.append((test_name, result))
            if result:
                logger.info(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                logger.error(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            logger.error(f"ğŸ’¥ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            test_results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ“Š æµ‹è¯•æ€»ç»“")
    logger.info(f"{'='*60}")
    
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
    
    logger.info(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼æ‰¹é‡å¤„ç†ä¼˜åŒ–æˆåŠŸï¼")
        logger.info("\nğŸš€ ä¼˜åŒ–å®Œæˆï¼ŒåŠŸèƒ½æå‡ï¼š")
        logger.info("  âœ… æŸ¥è¯¢é™åˆ¶è°ƒæ•´ä¸º5æ¡")
        logger.info("  âœ… æ™ºèƒ½è¿‡æ»¤æœªå¤„ç†è®°å½•")
        logger.info("  âœ… è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯")
        logger.info("  âœ… ä¼˜åŒ–çš„å¹¶å‘æ§åˆ¶")
        logger.info("  âœ… å®Œå–„çš„å¤„ç†æ‘˜è¦")
    else:
        logger.warning(f"âš ï¸ æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

if __name__ == "__main__":
    asyncio.run(main())
